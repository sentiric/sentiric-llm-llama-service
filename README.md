# ğŸ§  Sentiric LLM Llama Service (v2.5)

**Production-Ready**, yÃ¼ksek performanslÄ±, C++ tabanlÄ± yerel LLM Ã§Ä±karÄ±m motoru. Ã–zellikle **GerÃ§ek ZamanlÄ± Telefon AsistanÄ± (Voice AI)** senaryolarÄ± iÃ§in optimize edilmiÅŸ, **Qwen 2.5 3B** motoru ile gÃ¼Ã§lendirilmiÅŸtir.

[![CI - Build and Push Docker Image](https://github.com/sentiric/sentiric-llm-llama-service/actions/workflows/build-and-push.yml/badge.svg)](https://github.com/sentiric/sentiric-llm-llama-service/actions/workflows/build-and-push.yml)

## ğŸš€ Durum: STABLE (Ãœretim HazÄ±r)

Bu servis, **15 AralÄ±k 2025** itibarÄ±yla v2.5 sÃ¼rÃ¼mÃ¼ne yÃ¼kseltilmiÅŸ ve aÅŸaÄŸÄ±daki kritik yeteneklerle donatÄ±lmÄ±ÅŸtÄ±r:

-   âœ… **Phone-Call Ready Latency:** GPU hÄ±zlandÄ±rmasÄ± ile <300ms ilk token sÃ¼resi (TTFT).
-   âœ… **Qwen 2.5 3B Core:** TÃ¼rkÃ§e dil desteÄŸi ve talimat takibi (Instruction Following) iÃ§in sÄ±nÄ±fÄ±nÄ±n lideri.
-   âœ… **RAG (Retrieval-Augmented Generation):** DÄ±ÅŸ baÄŸlam verileriyle (Context Injection) halÃ¼sinasyonsuz yanÄ±tlar.
-   âœ… **Smart Context Pooling:** AynÄ± anda Ã§oklu aramayÄ± yÃ¶netebilen, thread-safe havuz mimarisi.
-   âœ… **Deep Observability:** Prometheus metrikleri, Trace ID takibi ve detaylÄ± yapÄ±landÄ±rÄ±lmÄ±ÅŸ loglar.

---

## ğŸ› ï¸ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### Ã–n Gereksinimler
-   Docker & Docker Compose
-   NVIDIA GPU (Tavsiye edilen: 6GB VRAM ve Ã¼zeri)
-   CUDA Toolkit 12.0+

### 1. BaÅŸlatma (Otomatik Kurulum)

Sistem, ilk aÃ§Ä±lÄ±ÅŸta gerekli `Qwen 2.5 3B` modelini otomatik olarak indirir.

```bash
# Servisi ve veritabanlarÄ±nÄ± baÅŸlat
make up

# LoglarÄ± izle (Model indirme sÃ¼recini gÃ¶rmek iÃ§in)
make logs
```

### 2. SaÄŸlÄ±k KontrolÃ¼

Model yÃ¼klendiÄŸinde servis `Healthy` durumuna geÃ§er:

```bash
curl http://localhost:16070/health
# YanÄ±t: {"status": "healthy", "model_ready": true, "capacity": ...}
```

### 3. Test Etme (CLI ile)

Dahili test aracÄ± ile bir RAG sorgusu gÃ¶nderin:

```bash
# Sigorta senaryosu Ã¶rneÄŸi
docker compose -f docker-compose.run.gpu.yml run --rm llm-cli \
  llm_cli generate "Mehmet Bey'in poliÃ§esi ne durumda?" \
  --rag-context "MÃ¼ÅŸteri: Mehmet Aslan. PoliÃ§e: Aktif. BitiÅŸ: 2026."
```

---

## âš™ï¸ YapÄ±landÄ±rma ve Profiller

Servis, statik model ayarlarÄ± (`profiles.json`) ile dinamik altyapÄ± ayarlarÄ±nÄ± (`.env`) birbirinden ayÄ±rÄ±r.

### Aktif Model Profili: `qwen25_3b_phone_assistant`

Bu profil, telefon gÃ¶rÃ¼ÅŸmeleri iÃ§in Ã¶zel olarak ayarlanmÄ±ÅŸtÄ±r:
-   **Model:** Qwen 2.5 3B Instruct
-   **Temperature:** 0.2 (TutarlÄ± ve ciddi yanÄ±tlar iÃ§in)
-   **Context Size:** 8192 Token
-   **System Prompt:** Ã‡aÄŸrÄ± merkezi asistanÄ± kimliÄŸi.

*FarklÄ± bir profil kullanmak iÃ§in `models/profiles.json` dosyasÄ±nÄ± inceleyin.*

### Temel Ortam DeÄŸiÅŸkenleri (`.env`)

| DeÄŸiÅŸken | VarsayÄ±lan | AÃ§Ä±klama |
|---|---|---|
| `LLM_LLAMA_SERVICE_GPU_LAYERS` | `100` | GPU'ya yÃ¼klenecek katman sayÄ±sÄ± (100 = TÃ¼mÃ¼). |
| `LLM_LLAMA_SERVICE_THREADS` | `Auto` | Ä°ÅŸlemci Ã§ekirdek limiti. |
| `LLM_LLAMA_SERVICE_KV_OFFLOAD` | `true` | KV Cache'i VRAM'de tut (HÄ±z iÃ§in kritik). |
| `LLM_LLAMA_SERVICE_PORT_GRPC` | `16071` | Ana iletiÅŸim portu. |

---

## ğŸ—ï¸ Mimari

```mermaid
graph TD
    Client[Gateway / Voice Service] -->|gRPC (mTLS)| GRPC_Server
    
    subgraph "LLM Service Container"
        GRPC_Server --> Engine[LLM Engine]
        HTTP_Server --> Engine
        
        Engine --> Batcher[Dynamic Batcher]
        Batcher --> Pool[Llama Context Pool]
        
        Pool -->|Acquire| GPU[(NVIDIA GPU)]
        Pool -->|Load| ModelFile[Qwen 2.5 GGUF]
    end
```

### Temel BileÅŸenler
1.  **Dynamic Batcher:** Gelen istekleri mikrosaniyeler iÃ§inde gruplayarak GPU verimini artÄ±rÄ±r.
2.  **Context Pool:** Her telefon gÃ¶rÃ¼ÅŸmesi iÃ§in izole bir bellek alanÄ± (Context) saÄŸlar.
3.  **Prompt Formatter:** RAG verisini ve geÃ§miÅŸi modelin anlayacaÄŸÄ± Ã¶zel formata Ã§evirir.

---

## ğŸ“Š Performans ReferanslarÄ±

**DonanÄ±m:** NVIDIA RTX 3060 (6GB VRAM)

| Metrik | DeÄŸer | AÃ§Ä±klama |
|---|---|---|
| **TTFT (Time To First Token)** | ~250ms | Ä°lk sesin Ã§Ä±kma sÃ¼resi. |
| **TPS (Tokens Per Second)** | ~55-60 | KonuÅŸma hÄ±zÄ± (Ä°nsan ortalamasÄ±nÄ±n 3 katÄ±). |
| **Max Concurrent Calls** | 4-5 | AynÄ± anda desteklenen aktif gÃ¶rÃ¼ÅŸme. |

---

## ğŸ“œ Lisans

Bu proje **AGPL-3.0** lisansÄ± altÄ±ndadÄ±r.