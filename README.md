# ğŸ§  Sentiric LLM Llama Service

**Sentiric LLM Llama Service**, yerel donanÄ±m Ã¼zerinde (on-premise) BÃ¼yÃ¼k Dil Modeli (LLM) Ã§Ä±karÄ±mÄ± saÄŸlayan, C++ ile yazÄ±lmÄ±ÅŸ yÃ¼ksek performanslÄ± bir uzman AI motorudur. `llama.cpp` kÃ¼tÃ¼phanesini temel alarak, popÃ¼ler aÃ§Ä±k kaynaklÄ± modelleri GGUF formatÄ±nda Ã§alÄ±ÅŸtÄ±rÄ±r.

Bu servis, `sentiric-contracts` v1.10.0+ API standardÄ±nÄ± uygular.

## ğŸ¯ Temel Sorumluluklar
- **Maksimum Performans:** C++ ve `llama.cpp` ile donanÄ±ma en yakÄ±n hÄ±zda LLM Ã§Ä±karÄ±mÄ±.
- **DÃ¼ÅŸÃ¼k Kaynak TÃ¼ketimi:** Kuantize edilmiÅŸ GGUF modelleri ile dÃ¼ÅŸÃ¼k bellek kullanÄ±mÄ±.
- **gRPC Streaming:** Metin yanÄ±tlarÄ±nÄ± token token Ã¼reterek dÃ¼ÅŸÃ¼k algÄ±lanan gecikme.
- **Dinamik SaÄŸlÄ±k KontrolÃ¼:** Modelin hazÄ±r olup olmadÄ±ÄŸÄ±nÄ± bildiren `/health` endpoint'i.

## ğŸ› ï¸ Derleme ve Ã‡alÄ±ÅŸtÄ±rma

### Ã–n KoÅŸullar
- Docker ve Docker Compose
- Git
- Bir adet GGUF formatÄ±nda LLM modeli (Ã–rn: `phi-3-mini-4k-instruct.Q4_K_M.gguf`)

### AdÄ±m AdÄ±m Kurulum

1.  **Repoyu Klonla ve Submodule'leri YÃ¼kle:**
    ```bash
    git clone --recurse-submodules https://github.com/sentiric/llm-llama-service.git
    cd llm-llama-service
    ```

2.  **Modeli HazÄ±rla:**
    - Proje kÃ¶k dizininde `models` adÄ±nda bir klasÃ¶r oluÅŸturun.
    - Ä°ndirdiÄŸiniz GGUF model dosyasÄ±nÄ± bu klasÃ¶rÃ¼n iÃ§ine kopyalayÄ±n. Ã–rnek:
    ```bash
    ./models/download.sh
    ```

3.  **YapÄ±landÄ±rmayÄ± DÃ¼zenle (Gerekirse):**
    - `docker-compose.yml` dosyasÄ±ndaki `LLM_LOCAL_SERVICE_MODEL_PATH` deÄŸiÅŸkenini, kendi model dosyanÄ±zÄ±n adÄ±yla gÃ¼ncelleyin.

4.  **Servisi BaÅŸlat:**
    ```bash
    docker compose up --build
    ```
    Ä°lk derleme birkaÃ§ dakika sÃ¼rebilir.

## âœ… DoÄŸrulama

-   **SaÄŸlÄ±k KontrolÃ¼:** `curl http://localhost:16060/health` komutunu Ã§alÄ±ÅŸtÄ±rÄ±n. `{"model_ready":true}` yanÄ±tÄ±nÄ± gÃ¶rmelisiniz.
-   **gRPC Test:** Servis Ã§alÄ±ÅŸÄ±rken, **ayrÄ± bir terminalde** aÅŸaÄŸÄ±daki komutu Ã§alÄ±ÅŸtÄ±rÄ±n.
    ```bash
    # Test istemcisini Ã§alÄ±ÅŸtÄ±r
    docker compose exec llm-llama-service grpc_test_client "TÃ¼rkiye'nin baÅŸkenti neresidir?"
    ```