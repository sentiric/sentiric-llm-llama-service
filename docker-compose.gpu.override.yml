# docker-compose.gpu.override.yml
services:
  llm-llama-service:
    build:
      context: .
      dockerfile: Dockerfile.gpu
    image: sentiric/llm-llama-service:local-gpu