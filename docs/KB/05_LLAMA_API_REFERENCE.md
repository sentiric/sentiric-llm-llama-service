 ğŸ’¡ KB-05: llama.cpp API HÄ±zlÄ± Referans KÄ±lavuzu (vB7415)

**Kapsam:** `llama.h` ve `common.h` dosyalarÄ±ndaki en kritik fonksiyonlarÄ±n, projemizdeki kullanÄ±m amaÃ§larÄ±na gÃ¶re kategorize edilmiÅŸ listesidir.

---

### 1. Kurulum ve YÃ¼kleme (Setup)

| Fonksiyon | Kaynak | AÃ§Ä±klama |
| :--- | :--- | :--- |
| `llama_backend_init` | `llama.h` | Global arka ucu baÅŸlatÄ±r (NUMA vb.). |
| `llama_model_default_params` | `llama.h` | VarsayÄ±lan model parametrelerini dÃ¶ndÃ¼rÃ¼r. |
| `llama_model_load_from_file` | `llama.h` | GGUF dosyasÄ±ndan modeli yÃ¼kler. |
| `llama_context_default_params` | `llama.h` | VarsayÄ±lan context parametrelerini dÃ¶ndÃ¼rÃ¼r. |
| **`llama_init_from_model`** | `llama.h` | YÃ¼klÃ¼ modelden bir Ã§Ä±karÄ±m oturumu (context) oluÅŸturur. |
| `llama_model_get_vocab` | `llama.h` | Modelin kelime daÄŸarcÄ±ÄŸÄ±na (`llama_vocab`) pointer dÃ¶ner. |

### 2. Kelime DaÄŸarcÄ±ÄŸÄ± ve Tokenizasyon (Vocab)

*Not: Bu fonksiyonlar artÄ±k `llama_vocab*` parametresi alÄ±r.*

| Fonksiyon | AÃ§Ä±klama |
| :--- | :--- |
| **`llama_tokenize`** | Metni token ID listesine Ã§evirir. `add_special` parametresi Ã¶nemlidir. |
| **`llama_token_to_piece`** | Token ID'yi metin parÃ§asÄ±na (string) Ã§evirir. |
| `llama_vocab_n_tokens` | Toplam token sayÄ±sÄ±nÄ± dÃ¶ner. |
| `llama_vocab_is_eog` | Token'Ä±n bitiÅŸ (End-Of-Generation/EOS/EOT) tokenÄ± olup olmadÄ±ÄŸÄ±nÄ± dÃ¶ner. |
| `llama_vocab_is_control` | Kontrol tokenÄ± olup olmadÄ±ÄŸÄ±nÄ± dÃ¶ner. |
| `llama_vocab_bos` / `eos` | Ã–zel tokenlarÄ±n ID'lerini dÃ¶ner. |

### 3. Ä°ÅŸ YÄ±ÄŸÄ±nÄ± (Batching) ve Ã‡Ä±karÄ±m (Inference)

| Fonksiyon | Kaynak | AÃ§Ä±klama |
| :--- | :--- | :--- |
| `llama_batch_init` | `llama.h` | Verilen kapasitede boÅŸ bir batch oluÅŸturur. |
| **`common_batch_add`** | `common.h` | Batch'e token ekleyen yardÄ±mcÄ± fonksiyondur (pos, seq_id, logits ayarlarÄ±nÄ± yapar). |
| `common_batch_clear` | `common.h` | Batch'i sÄ±fÄ±rlar (tekrar kullanÄ±m iÃ§in). |
| **`llama_decode`** | `llama.h` | Batch'teki tokenlarÄ± modele iÅŸler (Forward pass). KV Cache gÃ¼ncellenir. |
| `llama_get_logits_ith` | `llama.h` | Decode sonrasÄ±, belirtilen indexteki tokenÄ±n logit vektÃ¶rÃ¼nÃ¼ dÃ¶ner. |
| `llama_get_embeddings` | `llama.h` | (EÄŸer aktifse) Embedding vektÃ¶rÃ¼nÃ¼ dÃ¶ner. |

### 4. Bellek YÃ¶netimi (KV Cache)

*Not: TÃ¼m iÅŸlemler `llama_get_memory(ctx)` ile alÄ±nan nesne Ã¼zerinden yapÄ±lÄ±r.*

| Fonksiyon | AÃ§Ä±klama |
| :--- | :--- |
| **`llama_get_memory`** | Context'in bellek kontrolcÃ¼sÃ¼nÃ¼ (`llama_memory_t`) dÃ¶ner. |
| **`llama_memory_seq_rm`** | Belirtilen aralÄ±ktaki tokenlarÄ± bellekten siler. |
| `llama_memory_seq_add` | Belirtilen aralÄ±ktaki tokenlarÄ±n pozisyonlarÄ±nÄ± kaydÄ±rÄ±r (Context shifting). |
| `llama_memory_seq_cp` | Bir sequence'i kopyalar (Beam search veya parallel decoding iÃ§in). |
| `llama_memory_clear` | TÃ¼m belleÄŸi tamamen temizler. |

### 5. Ã–rnekleme (Sampling)

*Not: `llama_sampler` yapÄ±sÄ± kullanÄ±lÄ±r.*

| Fonksiyon | AÃ§Ä±klama |
| :--- | :--- |
| `llama_sampler_chain_init` | Yeni bir Ã¶rnekleme zinciri oluÅŸturur. |
| `llama_sampler_chain_add` | Zincire bir kural (sampler) ekler. |
| `llama_sampler_init_top_k` | Top-K Ã¶rnekleyici oluÅŸturur. |
| `llama_sampler_init_top_p` | Top-P (Nucleus) Ã¶rnekleyici oluÅŸturur. |
| `llama_sampler_init_temp` | SÄ±caklÄ±k (Temperature) Ã¶rnekleyici oluÅŸturur. |
| `llama_sampler_init_penalties` | Tekrar cezasÄ± (Repetition penalty) Ã¶rnekleyicisi oluÅŸturur. |
| **`llama_sampler_init_dist`** | OlasÄ±lÄ±k daÄŸÄ±lÄ±mÄ±na gÃ¶re rastgele seÃ§im yapan nihai Ã¶rnekleyici (Seed alÄ±r). |
| **`llama_sampler_init_greedy`** | En yÃ¼ksek olasÄ±lÄ±klÄ± tokenÄ± seÃ§en nihai Ã¶rnekleyici. |
| **`llama_sampler_sample`** | Logitleri iÅŸleyip zincir kurallarÄ±na gÃ¶re bir token seÃ§er. |
| **`llama_sampler_accept`** | SeÃ§ilen tokenÄ± zincire bildirir (Internal state gÃ¼ncellemesi iÃ§in). |

### 6. LoRA AdaptÃ¶rleri (Adapters)

*LoRA'lar modelin aÄŸÄ±rlÄ±klarÄ±nÄ± deÄŸiÅŸtirmeden ince ayar (fine-tune) yeteneÄŸi ekler.*

| Fonksiyon | Kaynak | AÃ§Ä±klama |
| :--- | :--- | :--- |
| **`llama_adapter_lora_init`** | `llama.h` | Verilen yoldan (`.gguf`) bir LoRA adaptÃ¶rÃ¼ yÃ¼kler ve `model` ile iliÅŸkilendirir. Pointer dÃ¶ner. |
| **`llama_set_adapter_lora`** | `llama.h` | YÃ¼klenmiÅŸ bir adaptÃ¶rÃ¼, belirtilen `scale` (gÃ¼Ã§) faktÃ¶rÃ¼ ile `ctx` (context)'e uygular. |
| `llama_rm_adapter_lora` | `llama.h` | Belirtilen adaptÃ¶rÃ¼ context'ten Ã§Ä±karÄ±r (etkisizleÅŸtirir). |
| `llama_clear_adapter_lora` | `llama.h` | Context Ã¼zerindeki **tÃ¼m** adaptÃ¶rleri temizler. |
| `llama_adapter_lora_free` | `llama.h` | AdaptÃ¶rÃ¼ manuel olarak bellekten siler. (Ã‡aÄŸrÄ±lmazsa `llama_model_free` otomatik siler). |
| `common_adapter_lora_info` | `common.h` | AdaptÃ¶r path'i ve scale deÄŸerini tutan yardÄ±mcÄ± struct. |

### 7. Kaynak Serbest BÄ±rakma (Cleanup)

| Fonksiyon | AÃ§Ä±klama |
| :--- | :--- |
| `llama_batch_free` | Batch belleÄŸini temizler. |
| `llama_sampler_free` | Sampler zincirini temizler. |
| `llama_free` | Context belleÄŸini temizler. |
| `llama_model_free` | Model belleÄŸini (ve baÄŸlÄ± LoRA'larÄ±) temizler. |
| `llama_backend_free` | KÃ¼tÃ¼phaneyi kapatÄ±r. |
```