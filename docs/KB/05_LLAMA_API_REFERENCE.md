# ğŸ’¡ KB-05: llama.cpp API HÄ±zlÄ± Referans KÄ±lavuzu

**AMAÃ‡:** Bu dokÃ¼man, `sentiric-llm-llama-service` projesinde sÄ±kÃ§a kullanÄ±lan `llama.cpp` API fonksiyonlarÄ±nÄ±n kategorize edilmiÅŸ bir listesini sunar. GeliÅŸtirme sÄ±rasÄ±nda hÄ±zlÄ± bir baÅŸvuru kaynaÄŸÄ± olarak tasarlanmÄ±ÅŸtÄ±r. API'nin baÄŸlayÄ±cÄ± kontratÄ± ve spesifik kullanÄ±m desenleri iÃ§in her zaman **[KB-04: Proje Ä°Ã§i API BaÄŸlayÄ±cÄ± KontratÄ±](./04_LLAMA_CPP_API_BINDING.md)** belgesine baÅŸvurulmalÄ±dÄ±r.

---

### Kategori 1: BaÅŸlatma ve YÃ¶netim (Initialization & Management)

| Fonksiyon | AÃ§Ä±klama |
| :--- | :--- |
| `llama_backend_init()` | `llama.cpp` altyapÄ±sÄ±nÄ± program baÅŸÄ±nda bir kez baÅŸlatÄ±r. |
| `llama_model_load_from_file()` | Bir `.gguf` model dosyasÄ±nÄ± diskten yÃ¼kler ve bir model nesnesi oluÅŸturur. |
| `llama_init_from_model()` | YÃ¼klenmiÅŸ bir modelden, asÄ±l Ã§Ä±karÄ±m iÅŸlemlerinin yapÄ±lacaÄŸÄ± `context`'i oluÅŸturur. |
| `llama_model_free()` | Model tarafÄ±ndan kullanÄ±lan belleÄŸi serbest bÄ±rakÄ±r. |
| `llama_free()` | Context tarafÄ±ndan kullanÄ±lan belleÄŸi serbest bÄ±rakÄ±r. |
| `llama_backend_free()` | Program sonunda altyapÄ±yÄ± kapatÄ±r. |

### Kategori 2: Bellek ve KV Cache YÃ¶netimi

| Fonksiyon | AÃ§Ä±klama |
| :--- | :--- |
| **`llama_get_memory(ctx)`** | Bir context'in bellek yÃ¶neticisi nesnesini (`llama_memory_t`) dÃ¶ndÃ¼rÃ¼r. |
| **`llama_memory_seq_rm()`** | **(KRÄ°TÄ°K)** Belirtilen bir sequence'in KV cache'inin bir kÄ±smÄ±nÄ± veya tamamÄ±nÄ± temizler. "Context Shifting" ve havuz temizliÄŸi iÃ§in bu kullanÄ±lÄ±r. |
| **`llama_memory_seq_add()`** | TemizlenmiÅŸ bir KV cache'e pozisyonel bir ofset ekler. "Context Shifting" iÃ§in gereklidir. |
| `llama_memory_seq_cp()` | Bir sequence'in KV cache'ini baÅŸka bir sequence'e kopyalar (Ä°leri seviye dallanma/forking senaryolarÄ± iÃ§in). |

### Kategori 3: Ã‡Ä±karÄ±m (Inference)

| Fonksiyon | AÃ§Ä±klama |
| :--- | :--- |
| `llama_batch_init()` | Token'larÄ± ve pozisyonlarÄ±nÄ± iÃ§eren bir "batch" (iÅŸ yÄ±ÄŸÄ±nÄ±) nesnesi oluÅŸturur. |
| `llama_decode(ctx, batch)` | Verilen "batch"i iÅŸler, modelin durumunu gÃ¼nceller ve logit'leri (bir sonraki token tahminleri) hesaplar. |
| `llama_get_logits_ith(ctx, i)` | Son `llama_decode` Ã§aÄŸrÄ±sÄ±ndan sonra, belirtilen `i`. pozisyondaki token iÃ§in logit'leri dÃ¶ndÃ¼rÃ¼r. |
| `llama_batch_free()` | OluÅŸturulan "batch" nesnesini serbest bÄ±rakÄ±r. |

### Kategori 4: Tokenizasyon (Tokenization)

| Fonksiyon | AÃ§Ä±klama |
| :--- | :--- |
| `llama_model_get_vocab()` | Modelin kelime daÄŸarcÄ±ÄŸÄ± (`vocab`) nesnesini dÃ¶ndÃ¼rÃ¼r. |
| `llama_tokenize()` | Bir metin parÃ§asÄ±nÄ± (`char*`) bir token dizisine (`llama_token[]`) Ã§evirir. |
| `llama_token_to_piece()` | Tek bir token'Ä±, okunabilir bir metin parÃ§asÄ±na (`char*`) Ã§evirir. |

### Kategori 5: Ã–rnekleme (Sampling)

| Fonksiyon | AÃ§Ä±klama |
| :--- | :--- |
| `llama_sampler_chain_init()` | Birden fazla Ã¶rnekleme kuralÄ±nÄ± (top-k, top-p, sÄ±caklÄ±k vb.) bir araya getiren bir zincir oluÅŸturur. |
| `llama_sampler_chain_add()` | Ã–rnekleme zincirine yeni bir kural ekler (Ã¶rn: `llama_sampler_init_top_k()`). |
| `llama_sampler_sample()` | Verilen logit'lere, zincirdeki tÃ¼m kurallarÄ± uygulayarak nihai bir token seÃ§er. |
| `llama_sampler_accept()` | SeÃ§ilen token'Ä± zincire "kabul ettirir". Bu, tekrarlama cezasÄ± gibi durumlarÄ± gÃ¼nceller. |
| `llama_sampler_free()` | Ã–rnekleme zincirini bellekten temizler. |

---
