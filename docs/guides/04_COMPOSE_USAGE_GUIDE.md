# ğŸ³ Docker Compose KullanÄ±m Rehberi

## ğŸ“‹ Genel BakÄ±ÅŸ

Bu proje, farklÄ± kullanÄ±m senaryolarÄ± iÃ§in optimize edilmiÅŸ multiple Docker Compose dosyalarÄ± kullanÄ±r:

### ğŸ—ï¸ Compose Dosya Mimarisi
- **`docker-compose.yml`** - Temel yapÄ±landÄ±rma (asla tek baÅŸÄ±na kullanÄ±lmaz)
- **`docker-compose.cpu.yml`** - Production CPU profili
- **`docker-compose.gpu.yml`** - Production GPU profili  
- **`docker-compose.override.yml`** - Local development (CPU)
- **`docker-compose.gpu.override.yml`** - Local development (GPU)
- **`docker-compose.run.gpu.yml`** - CLI iÃ§in GPU konteyneri
- **`docker-compose.open-webui.yml`** - Open WebUI ArayÃ¼zÃ¼

---

## ğŸš€ KULLANIM SENARYOLARI

### 1. ğŸ–¥ï¸ PRODUCTION - CPU DaÄŸÄ±tÄ±mÄ±

**AmaÃ§:** Pre-built imaj ile production CPU ortamÄ±

```bash
# GitHub Container Registry'den imajÄ± Ã§ek ve Ã§alÄ±ÅŸtÄ±r
docker compose -f docker-compose.yml -f docker-compose.cpu.yml up -d

# Servisi durdur
docker compose -f docker-compose.yml -f docker-compose.cpu.yml down
```

**Ã–zellikler:**
- âœ… Pre-built imaj kullanÄ±r (`ghcr.io/sentiric/sentiric-llm-llama-service:latest`)
- âœ… Optimize edilmiÅŸ CPU ayarlarÄ±
- âœ… Production-ready health checks
- âœ… mTLS gÃ¼venlik aktif

---

### 2. ğŸ® PRODUCTION - GPU DaÄŸÄ±tÄ±mÄ±

**AmaÃ§:** Pre-built imaj ile production GPU ortamÄ±

```bash
# GPU imajÄ±nÄ± Ã§ek ve Ã§alÄ±ÅŸtÄ±r
docker compose -f docker-compose.yml -f docker-compose.gpu.yml up -d

# Servisi durdur
docker compose -f docker-compose.yml -f docker-compose.gpu.yml down
```

**GPU AyarlarÄ±:**
```yaml
- LLM_LLAMA_SERVICE_GPU_LAYERS=28
- NVIDIA_VISIBLE_DEVICES=all
```

**Ã–zellikler:**
- âœ… Pre-built GPU imajÄ±
- âœ… NVIDIA GPU desteÄŸi
- âœ… Optimize edilmiÅŸ 6GB VRAM ayarlarÄ±
- âœ… Otomatik GPU resource allocation

---

### 3. ğŸ”§ LOCAL DEVELOPMENT - CPU GeliÅŸtirme

**AmaÃ§:** Yerel kod deÄŸiÅŸiklikleriyle development

```bash
# Kaynaktan build et ve Ã§alÄ±ÅŸtÄ±r (override otomatik kullanÄ±lÄ±r)
docker compose up --build -d

# LoglarÄ± izle
docker compose logs -f llm-llama-service

# Servisi durdur
docker compose down
```

**Ã–zellikler:**
- âœ… Yerel kod deÄŸiÅŸiklikleriyle otomatik rebuild
- âœ… `docker-compose.override.yml` otomatik kullanÄ±lÄ±r
- âœ… GeliÅŸtirme iÃ§in optimize edilmiÅŸ ayarlar
- âœ… CLI konteyneri dahil

---

### 4. ğŸ¯ LOCAL DEVELOPMENT - GPU GeliÅŸtirme

**AmaÃ§:** Yerel GPU ile development ve test

```bash
# GPU iÃ§in build et ve Ã§alÄ±ÅŸtÄ±r
docker compose -f docker-compose.yml -f docker-compose.gpu.yml -f docker-compose.gpu.override.yml up --build -d

# LoglarÄ± izle
docker compose -f docker-compose.yml -f docker-compose.gpu.yml -f docker-compose.gpu.override.yml logs -f

# Servisi durdur
docker compose -f docker-compose.yml -f docker-compose.gpu.yml -f docker-compose.gpu.override.yml down
```

**Optimize GPU AyarlarÄ± (6GB VRAM):**
```yaml
- LLM_LLAMA_SERVICE_GPU_LAYERS=28
- LLM_LLAMA_SERVICE_CONTEXT_SIZE=1024
- LLM_LLAMA_SERVICE_THREADS=1
- LLM_LLAMA_SERVICE_THREADS_BATCH=1
- LLM_LLAMA_SERVICE_ENABLE_BATCHING=false
- LLM_LLAMA_SERVICE_ENABLE_WARM_UP=true
```

---

### 5. ğŸŒ OPEN WEBUI ENTEGRASYONU (YENÄ°)

**AmaÃ§:** Servisi test etmek veya kullanmak iÃ§in modern, ChatGPT benzeri bir arayÃ¼z baÅŸlatmak.

```bash
# WebUI'yi BaÅŸlat (Port: 3000)
make up-ui

# Veya Manuel Olarak:
docker compose -f docker-compose.open-webui.yml up -d
```

**EriÅŸim:**
- TarayÄ±cÄ±: `http://localhost:3000`
- Ä°lk aÃ§Ä±lÄ±ÅŸta bir yÃ¶netici hesabÄ± oluÅŸturmanÄ±z istenecektir.

**Ã–zellikler:**
- âœ… `sentiric-net` aÄŸÄ±na otomatik baÄŸlanÄ±r.
- âœ… Modelleri otomatik tanÄ±r (`/v1/models` Ã¼zerinden).
- âœ… Veriler `open-webui` volume'Ã¼nde kalÄ±cÄ± saklanÄ±r.

---

### 6. ğŸ› ï¸ CLI ARAÃ‡LARI - GPU OrtamÄ±nda

**AmaÃ§:** GPU destekli CLI komutlarÄ±nÄ± Ã§alÄ±ÅŸtÄ±rma

```bash
# Health check
docker compose -f docker-compose.run.gpu.yml run --rm llm-cli llm_cli health

# Metin Ã¼retme
docker compose -f docker-compose.run.gpu.yml run --rm llm-cli llm_cli generate "Merhaba dÃ¼nya"

# RAG testi (run_request.sh alternatifi)
docker compose -f docker-compose.run.gpu.yml run --rm llm-cli llm_cli generate "Soru" --rag-context "Context metni"
```

**Ã–zellikler:**
- âœ… GeÃ§ici konteyner (--rm)
- âœ… GPU eriÅŸimi
- âœ… mTLS sertifikalarÄ±
- âœ… Servis aÄŸÄ±na baÄŸlÄ±

---

## âš™ï¸ ORTAM DEÄÄ°ÅKENLERÄ° REFERANSI

### Temel Ayarlar
```bash
# Model
LLM_LLAMA_SERVICE_MODEL_ID=ggml-org/gemma-3-1b-it-qat-GGUF
LLM_LLAMA_SERVICE_MODEL_FILENAME=gemma-3-1b-it-qat-Q4_0.gguf

# Performans
LLM_LLAMA_SERVICE_THREADS=1
LLM_LLAMA_SERVICE_CONTEXT_SIZE=1024
LLM_LLAMA_SERVICE_GPU_LAYERS=0  # CPU: 0, GPU: 28
```

### Yeni GeliÅŸmiÅŸ Ã–zellikler
```bash
# Warm-up (Ã–nerilen: true)
LLM_LLAMA_SERVICE_ENABLE_WARM_UP=true

# Dynamic Batching (Sadece THREADS > 1 iÃ§in)
LLM_LLAMA_SERVICE_ENABLE_BATCHING=false
LLM_LLAMA_SERVICE_MAX_BATCH_SIZE=1
LLM_LLAMA_SERVICE_BATCH_TIMEOUT_MS=10
```

### GÃ¼venlik
```bash
# mTLS sertifikalarÄ±
GRPC_TLS_CA_PATH=../sentiric-certificates/certs/ca.crt
LLM_LLAMA_SERVICE_CERT_PATH=../sentiric-certificates/certs/llm-llama-service-chain.crt
LLM_LLAMA_SERVICE_KEY_PATH=../sentiric-certificates/certs/llm-llama-service.key
```

---

## ğŸš¨ SIK KARÅILAÅILAN SORUNLAR

### 1. "orphan containers" UyarÄ±sÄ±
```bash
# Ã‡Ã¶zÃ¼m: --remove-orphans kullan
docker compose down --remove-orphans
```

### 2. GPU Bellek HatasÄ±
```bash
# Ã‡Ã¶zÃ¼m: GPU layers azalt
LLM_LLAMA_SERVICE_GPU_LAYERS=24
LLM_LLAMA_SERVICE_THREADS=1
```

### 3. mTLS BaÄŸlantÄ± HatasÄ±
```bash
# Ã‡Ã¶zÃ¼m: Sertifika yollarÄ±nÄ± kontrol et
ls -la ../sentiric-certificates/certs/
```

### 4. Open WebUI "Network Problem" HatasÄ±
**Neden:** WebUI konteyneri LLM servisine ulaÅŸamÄ±yor.
**Ã‡Ã¶zÃ¼m:** `make up-ui` kullanÄ±n veya her iki konteynerin de `sentiric-net` aÄŸÄ±nda olduÄŸundan emin olun. URL olarak `http://llm-llama-service:16070` kullanÄ±n.

---

## ğŸ”„ HIZLI REFERANS TABLOSU

| Senaryo | Komut | Build | GPU | Use Case |
|---------|--------|--------|-----|----------|
| Production CPU | `-f docker-compose.yml -f docker-compose.cpu.yml` | âŒ | âŒ | Production |
| Production GPU | `-f docker-compose.yml -f docker-compose.gpu.yml` | âŒ | âœ… | Production |
| Dev CPU | `docker compose up --build -d` | âœ… | âŒ | GeliÅŸtirme |
| Dev GPU | `-f docker-compose.yml -f docker-compose.gpu.yml -f docker-compose.gpu.override.yml` | âœ… | âœ… | GeliÅŸtirme |
| Open WebUI | `make up-ui` | âŒ | âŒ | UI / Chat |
| CLI GPU | `-f docker-compose.run.gpu.yml run --rm llm-cli` | âŒ | âœ… | Test |

---
