# ğŸ“‹ LLM Llama Service - Anayasa Uyum ve GeliÅŸtirme GÃ¶rev Listesi (Revizyon 4 - TamamlandÄ±)

**Belge AmacÄ±:** Bu dokÃ¼man, `sentiric-llm-llama-service` projesinin, `sentiric-governance` anayasasÄ±nda belirtilen mimari standartlara tam uyumlu, "production-ready" bir bileÅŸen haline getirilmesi iÃ§in gereken gÃ¶revleri tanÄ±mlar.

---

## âœ… TAMAMLANAN GÃ–REVLER

-   **[âœ“] TASK ID: `LLM-SEC-001`**: gRPC iletiÅŸimi mTLS ile ÅŸifrelendi.
-   **[âœ“] TASK ID: `LLM-BUG-001`**: gRPC istek parametreleri (sampling) artÄ±k dinamik olarak iÅŸleniyor.
-   **[âœ“] TASK ID: `LLM-OPS-001`**: Ortama duyarlÄ± yapÄ±landÄ±rÄ±lmÄ±ÅŸ loglama (JSON/konsol) implemente edildi.
-   **[âœ“] TASK ID: `LLM-BUILD-001`**: `llama.cpp` baÄŸÄ±mlÄ±lÄ±ÄŸÄ± belirli bir commite sabitlendi.
-   **[âœ“] TASK ID: `LLM-REFACTOR-001`**: `ModelManager` sorumluluÄŸu `LLMEngine` iÃ§ine taÅŸÄ±ndÄ±, mimari temizlendi.
-   **[âœ“] TASK ID: `LLM-API-002`**: API kontratÄ±, `sentiric-contracts v1.11.0` ile uyumlu hale getirilerek zengin diyalog yÃ¶netimi yeteneÄŸi kazandÄ±rÄ±ldÄ±.
-   **[âœ“] TASK ID: `LLM-FEATURE-001`**: VCA entegrasyonu tamamlandÄ±. Servis artÄ±k stream sonunda `prompt_tokens` ve `completion_tokens` sayÄ±larÄ±nÄ± raporlamaktadÄ±r.

---

**TÃ¼m planlanan gÃ¶revler tamamlanmÄ±ÅŸtÄ±r. Servis, Ã¼retim ortamÄ±na daÄŸÄ±tÄ±lmaya hazÄ±rdÄ±r.**

---

#### **FAZ 1: TEMELÄ° GÃœÃ‡LENDÄ°RME VE KÃ–PRÃœYÃœ Ä°NÅA ETME**

-   **[ ] TASK ID: `LLM-API-003` - OpenAI Uyumlu API Endpoint'i OluÅŸturma**
    *   **AÃ§Ä±klama:** `http_server.cpp`'ye, OpenAI API standardÄ±yla %100 uyumlu bir `/v1/chat/completions` endpoint'i eklenecektir. Bu endpoint hem streaming hem de non-streaming cevaplarÄ± destekleyecektir.
    *   **Kabul Kriterleri:**
        *   `llm-llama-service`, Postman veya benzeri bir araÃ§la gÃ¶nderilen standart bir OpenAI `chat/completions` isteÄŸine baÅŸarÄ±lÄ± bir ÅŸekilde cevap verebilmelidir.
        *   Ä°stek formatÄ± (`{"messages": [...]}`) ve cevap formatÄ± (`{"choices": [...]}`) OpenAI dokÃ¼mantasyonu ile birebir uyumlu olmalÄ±dÄ±r.
        *   **GÃ¼venlik Notu:** Bu endpoint doÄŸrudan dÄ±ÅŸ dÃ¼nyaya aÃ§Ä±lmayacak, platformun gelecekteki `api-gateway-service`'i tarafÄ±ndan kullanÄ±lmak Ã¼zere tasarlanacaktÄ±r.

-   **[ ] TASK ID: `LLM-PERF-001` - Adaptif Dinamik Batching MekanizmasÄ±nÄ± Uygulama**
    *   **AÃ§Ä±klama:** `llm_engine`, gelen istekleri donanÄ±m kapasitesine gÃ¶re akÄ±llÄ±ca gruplayarak GPU'ya tek seferde gÃ¶nderecek "Adaptif Batching" mekanizmasÄ±nÄ± implemente edecektir.
    *   **Kabul Kriterleri:**
        *   Servis baÅŸlangÄ±cÄ±nda, `n_gpu_layers` ve mevcut VRAM'e gÃ¶re mantÄ±klÄ± bir `max_batch_size` deÄŸeri otomatik olarak belirlenmelidir.
        *   DÃ¼ÅŸÃ¼k VRAM'li sistemlerde (Ã¶rn: 6GB GPU), `max_batch_size` otomatik olarak `1` veya `2` gibi gÃ¼venli bir deÄŸere ayarlanmalÄ±dÄ±r.
        *   YÃ¼ksek VRAM'li sistemlerde, `docker-compose.yml`'de belirtilen `LLM_LLAMA_SERVICE_MAX_BATCH_SIZE` deÄŸerini kullanmalÄ±dÄ±r.
        *   `llm_cli benchmark --concurrent 4` gibi bir komutla, batching'in saniye baÅŸÄ±na token (TPS) Ã¼retimini artÄ±rdÄ±ÄŸÄ± kanÄ±tlanmalÄ±dÄ±r.

---

#### **FAZ 2: VÄ°ZYONU PROTOTÄ°PLEME**

-   **[ ] TASK ID: `UI-PRO-001` - "Sentiric Studio" Prototip ArayÃ¼zÃ¼nÃ¼ GeliÅŸtirme**
    *   **AÃ§Ä±klama:** Deepseek AI tarafÄ±ndan tasarlanan HTML/CSS temel alÄ±narak, Vue.js veya React kullanÄ±larak fonksiyonel bir web arayÃ¼zÃ¼ oluÅŸturulacaktÄ±r. Bu arayÃ¼z, Faz 1'de oluÅŸturulan `/v1/chat/completions` endpoint'ini kullanarak `llm-llama-service` ile konuÅŸacaktÄ±r.
    *   **Kabul Kriterleri (Ä°lk SÃ¼rÃ¼m iÃ§in):**
        *   KullanÄ±cÄ±, ana sohbet ekranÄ± Ã¼zerinden mesaj gÃ¶nderip anlÄ±k (streaming) cevap alabilmelidir.
        *   Sol paneldeki "Sistem Promptu" ve "RAG Context" alanlarÄ± Ã§alÄ±ÅŸÄ±r durumda olmalÄ± ve `llm-llama-service`'e gÃ¶nderilen isteÄŸe dahil edilmelidir.
        *   SaÄŸ paneldeki metrikler (TTFT, TPS) yaklaÅŸÄ±k olarak hesaplanÄ±p gÃ¶sterilmelidir.
        *   Bu arayÃ¼z, gelecekte `governance`'da tanÄ±mlanan diÄŸer servislerle (Ã¶rn: `knowledge-service`'ten RAG kaynaklarÄ±nÄ± listelemek) konuÅŸabilecek ÅŸekilde modÃ¼ler tasarlanmalÄ±dÄ±r.

---

