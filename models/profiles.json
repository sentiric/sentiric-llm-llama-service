{
  "active_profile": "qwen3_4b_agent",
  "profiles": {
    "qwen3_4b_agent": {
      "display_name": "Sentiric Agent (Qwen 3 4B)",
      "description": "Smartest model. Uses Chain of Thought.",
      "category": "Production",
      "model_id": "ggml-org/Qwen3-4B-GGUF",
      "filename": "Qwen3-4B-Q4_K_M.gguf",
      "context_size": 8192,
      "gpu_layers": 100,
      "temperature": 0.3,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "templates": {
        "system_prompt": "You are a customer service agent for Sentiric. You HAVE access to the user's CRM data. Use the provided [CONTEXT] to answer. Do not say you cannot access data. Be brief and direct.",
        "rag_prompt": "[CONTEXT]\n{{rag_context}}\n[/CONTEXT]\n\nUser Question: {{user_prompt}}"
      }
    },
    "qwen2_3B": {
      "display_name": "Sentiric Agent (Qwen 2.5 3B)",
      "category": "Production",
      "model_id": "ggml-org/Qwen2.5-Coder-3B-Instruct-Q8_0-GGUF",
      "filename": "qwen2.5-coder-3b-instruct-q8_0.gguf",
      "context_size": 8192,
      "gpu_layers": 100,
      "temperature": 0.1,
      "templates": {
        "system_prompt": "You are a helpful assistant. Use the provided context to answer. Be extremely concise. No markdown.",
        "rag_prompt": "Context: {{rag_context}}\n\nQuestion: {{user_prompt}}"
      }
    },
    "ministral_3b_realtime": {
      "display_name": "Sentiric Realtime (Ministral 3B)",
      "category": "Realtime",
      "model_id": "ggml-org/Ministral-3-3B-Instruct-2512-GGUF",
      "filename": "Ministral-3-3B-Instruct-2512-Q8_0.gguf",
      "context_size": 8192,
      "gpu_layers": 100,
      "temperature": 0.2,
      "templates": {
        "system_prompt": "You are a helpful assistant. Answer based on the context provided below.",
        "rag_prompt": "Context Data:\n{{rag_context}}\n\nInstruction: Answer the user's question using ONLY the data above.\nUser: {{user_prompt}}"
      }
    },
    "gemma_1b_ultrafast": {
      "display_name": "Sentiric Edge (Gemma 1B)",
      "category": "Fallback",
      "model_id": "ggml-org/gemma-3-1b-it-GGUF",
      "filename": "gemma-3-1b-it-Q4_K_M.gguf",
      "context_size": 2048,
      "gpu_layers": 100,
      "temperature": 0.1,
      "templates": {
        "system_prompt": "Answer briefly.",
        "rag_prompt": "Info: {{rag_context}}\nQuestion: {{user_prompt}}"
      }
    },
    "gemma_4b": {
      "display_name": "Sentiric Edge (Gemma 4B)",
      "category": "Fallback",
      "model_id": "ggml-org/gemma-3-4b-it-GGUF",
      "filename": "gemma-3-4b-it-Q4_K_M.gguf",
      "context_size": 2048,
      "gpu_layers": 100,
      "temperature": 0.1,
      "templates": {
        "system_prompt": "Answer briefly.",
        "rag_prompt": "Info: {{rag_context}}\nQuestion: {{user_prompt}}"
      }
    }
  }
}