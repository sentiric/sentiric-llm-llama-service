{
  "active_profile": "default",
  "profiles": {
    "default": {
      "description": "Dengeli Türkçe Performans (Önerilen - Llama 3.2 3B)",
      "model_id": "bartowski/Llama-3.2-3B-Instruct-GGUF",
      "filename": "Llama-3.2-3B-Instruct-Q6_K.gguf",
      "context_size": 8192,
      "gpu_layers": 100,
      "temperature": 0.7,
      "system_prompt": "Sen yardımsever bir Türk asistanısın."
    },
    "tr_performance": {
      "description": "Yüksek zeka, 12GB+ VRAM gerektirir (Llama 3.1 8B)",
      "model_id": "bartowski/Meta-Llama-3.1-8B-Instruct-GGUF",
      "filename": "Meta-Llama-3.1-8B-Instruct-Q5_K_M.gguf",
      "context_size": 8192,
      "gpu_layers": 33,
      "temperature": 0.6,
      "system_prompt": "Sen detaylı düşünen bir uzmansın."
    },
    "coding_assistant": {
      "description": "Yazılım geliştirme (Qwen 2.5 7B) - 6GB VRAM Optimized",
      "model_id": "Qwen/Qwen2.5-Coder-7B-Instruct-GGUF",
      "filename": "qwen2.5-coder-7b-instruct-q5_k_m.gguf",
      "context_size": 8192,
      "gpu_layers": 30,
      "temperature": 0.2,
      "system_prompt": "You are an expert coding assistant."
    },
    "uncensored_creative": {
      "description": "Filtresiz Model (Llama 3 Abliterated)",
      "model_id": "bartowski/Meta-Llama-3-8B-Instruct-abliterated-v3-GGUF",
      "filename": "Meta-Llama-3-8B-Instruct-abliterated-v3-Q4_K_M.gguf",
      "context_size": 8192,
      "gpu_layers": 100,
      "temperature": 0.9,
      "system_prompt": "You are a creative storyteller."
    }
  }
}