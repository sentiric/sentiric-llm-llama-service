{
  "active_profile": "llama3_1b_q4",
  "profiles": {
    "qwen3_4b_q5": {
      "display_name": "Qwen 3 (4B, Q5_K_M)",
      "description": "~2.8 GB VRAM. Akıl yürüten (Reasoning) yetenekli model.",
      "category": "Reasoning",
      "model_id": "Qwen/Qwen3-4B-GGUF",
      "filename": "Qwen3-4B-Q5_K_M.gguf",
      "context_size": 8192,
      "gpu_layers": 100,
      "temperature": 0.6,
      "system_prompt": "Sen yardımsever ve zeki bir asistansın. Türkçe cevap ver."
    },
    "gemma3_1b_q8": {
      "display_name": "Gemma 3 (1B, Q8_0)",
      "description": "~1.8 GB VRAM. Çok hızlı, düşük kaynak.",
      "category": "Speed",
      "model_id": "ggml-org/gemma-3-1b-it-GGUF",
      "filename": "gemma-3-1b-it-Q8_0.gguf",
      "context_size": 4096,
      "gpu_layers": 100,
      "temperature": 0.7,
      "system_prompt": "Sen yardımsever bir asistansın."
    },
    "llama3_1b_q4": {
      "display_name": "Llama 3.2 (1B, Q4_K_M)",
      "description": "~0.8 GB VRAM. Ultra hafif.",
      "category": "Speed",
      "model_id": "bartowski/Llama-3.2-1B-Instruct-GGUF",
      "filename": "Llama-3.2-1B-Instruct-Q4_K_M.gguf",
      "context_size": 8192,
      "gpu_layers": 100,
      "temperature": 0.6,
      "system_prompt": "Sen yardımsever bir asistansın."
    },
    "phi3_mini_4k_q4": {
      "display_name": "Phi-3 Mini (3.8B, Q4_K_M)",
      "description": "~2.2 GB VRAM. Kodlama ve mantıkta güçlü.",
      "category": "Coding",
      "model_id": "microsoft/Phi-3-mini-4k-instruct-gguf",
      "filename": "Phi-3-mini-4k-instruct-q4.gguf",
      "context_size": 4096,
      "gpu_layers": 100,
      "temperature": 0.5,
      "system_prompt": "Sen uzman bir yazılım mühendisisin."
    }
  }
}