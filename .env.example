# ==============================================================================
# üåç GLOBAL AYARLAR
# ==============================================================================
ENV="development"
LOG_LEVEL="INFO"
ENV_FILE_PATH=.env

# Sentiric Ecosystem Paths
CONFIG_REPO_PATH=../sentiric-config
ASSETS_REPO_PATH=../sentiric-assets

# --- Security (mTLS) ---
CERTIFICATES_REPO_PATH=../sentiric-certificates
GRPC_TLS_CA_PATH=/sentiric-certificates/certs/ca.crt

# GPU Settings
NVIDIA_VISIBLE_DEVICES=all
NVIDIA_DISABLE_REQUIRE=true

# ==============================================================================
# üÜî PROJE Kƒ∞MLƒ∞ƒûƒ∞ VE Aƒû
# ==============================================================================
PROJECT_NAME="sentiric"
PROJECT_TLD="cloud"

# Network
NETWORK_NAME="sentiric.cloud"
NETWORK_SUBNET=10.88.0.0/16
NETWORK_GATEWAY=10.88.0.1



# Discovery Service (DNS)
DISCOVERY_SERVICE_IPV4_ADDRESS=10.88.5.1
DISCOVERY_DNS_SEARCH_DOMAIN="service.sentiric.cloud"

# ==============================================================================
# üß† LLM SERVICE YAPILANDIRMASI
# ==============================================================================
# Service Addresses
LLM_LLAMA_SERVICE_HOST=llm-llama-service
LLM_LLAMA_SERVICE_IPV4_ADDRESS=10.88.60.7
LLM_LLAMA_SERVICE_HTTP_PORT=16070
LLM_LLAMA_SERVICE_GRPC_PORT=16071
LLM_LLAMA_SERVICE_METRICS_PORT=16072
LLM_LLAMA_SERVICE_LISTEN_ADDRESS=0.0.0.0

# Model y√∂netimi
LLM_LLAMA_SERVICE_LOG_LEVEL=info
LLM_LLAMA_SERVICE_MODEL_DIR=/models

# ------------------------------------------------------------------------------
# [YENƒ∞ Sƒ∞STEM] Profil Tabanlƒ± Y√∂netim (profiles.json)
# ------------------------------------------------------------------------------
# Sistem artƒ±k modelleri 'models/profiles.json' dosyasƒ±ndan okur ve y√∂netir.
# A≈üaƒüƒ±daki model ayarlarƒ±, SADECE profil dosyasƒ± bulunamazsa veya okunamazsa
# "Fallback" (Yedek) olarak kullanƒ±lƒ±r.
#
# Varsayƒ±lan Yedek Model: Llama-3.2-3B (Hƒ±zlƒ± ve D√º≈ü√ºk VRAM)
# ------------------------------------------------------------------------------

LLM_LLAMA_SERVICE_MODEL_ID=bartowski/Llama-3.2-3B-Instruct-GGUF
LLM_LLAMA_SERVICE_MODEL_FILENAME=Llama-3.2-3B-Instruct-Q6_K.gguf

# --- Performans Varsayƒ±lanlarƒ± (Fallback) ---
# Bu deƒüerler de profil tarafƒ±ndan ezilir.
LLM_LLAMA_SERVICE_GPU_LAYERS=100        # -1 veya 100: Hepsi GPU'da
LLM_LLAMA_SERVICE_CONTEXT_SIZE=8192     # Standart Context
LLM_LLAMA_SERVICE_THREADS=4             # CPU Thread Sayƒ±sƒ±
LLM_LLAMA_SERVICE_THREADS_BATCH=4

# --- Bellek Optimizasyonu ---
LLM_LLAMA_SERVICE_USE_MMAP=true         # Model y√ºklemesini hƒ±zlandƒ±rƒ±r
LLM_LLAMA_SERVICE_KV_OFFLOAD=true       # KV Cache'i GPU'ya ta≈üƒ±r (Hƒ±z i√ßin kritik)
LLM_LLAMA_SERVICE_NUMA=disabled         # NUMA desteƒüi (Genellikle disabled)
LLM_LLAMA_SERVICE_FLASH_ATTN=true       # Flash Attention (VRAM tasarrufu)

# --- Dynamic Batching & E≈üzamanlƒ±lƒ±k ---
# Bu ayarlar globaldir ve profillerden baƒüƒ±msƒ±z √ßalƒ±≈üƒ±r.
LLM_LLAMA_SERVICE_ENABLE_BATCHING=true
LLM_LLAMA_SERVICE_MAX_BATCH_SIZE=8      # E≈üzamanlƒ± i≈ülenebilecek maksimum istek
LLM_LLAMA_SERVICE_BATCH_TIMEOUT_MS=5    # D√º≈ü√ºk gecikme i√ßin bekleme s√ºresi
LLM_LLAMA_SERVICE_ENABLE_WARM_UP=true   # Ba≈ülangƒ±√ßta GPU'yu ƒ±sƒ±tƒ±r

# --- Sampling Varsayƒ±lanlarƒ± ---
# ƒ∞stek i√ßinde parametre gelmezse bunlar kullanƒ±lƒ±r.
LLM_LLAMA_SERVICE_DEFAULT_MAX_TOKENS=1024
LLM_LLAMA_SERVICE_DEFAULT_TEMPERATURE=0.7
LLM_LLAMA_SERVICE_DEFAULT_TOP_K=40
LLM_LLAMA_SERVICE_DEFAULT_TOP_P=0.95
LLM_LLAMA_SERVICE_DEFAULT_REPEAT_PENALTY=1.1

# --- Gateway Integration ---
LLM_WORKER_GROUP="default"
# LLM_GATEWAY_ADDRESS="10.88.x.x:50051" # Opsiyonel

# --- G√ºvenlik ---
LLM_LLAMA_SERVICE_CERT_PATH=/sentiric-certificates/certs/llm-llama-service-chain.crt
LLM_LLAMA_SERVICE_KEY_PATH=/sentiric-certificates/certs/llm-llama-service.key