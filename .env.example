# ==============================================================================
# ğŸŒ GLOBAL AYARLAR
# ==============================================================================
ENV="development"
LOG_LEVEL="INFO"
ENV_FILE_PATH=.env

# Sentiric Ecosystem Paths
CONFIG_REPO_PATH=../sentiric-config
ASSETS_REPO_PATH=../sentiric-assets

# --- Security (mTLS) ---
CERTIFICATES_REPO_PATH=../sentiric-certificates
GRPC_TLS_CA_PATH=/sentiric-certificates/certs/ca.crt

# GPU Settings
NVIDIA_VISIBLE_DEVICES=all
NVIDIA_DISABLE_REQUIRE=true

# ==============================================================================
# ğŸ†” PROJE KÄ°MLÄ°ÄÄ° VE AÄ
# ==============================================================================
PROJECT_NAME="sentiric"
PROJECT_TLD="cloud"

# Network
NETWORK_NAME="sentiric.cloud"
NETWORK_SUBNET=10.88.0.0/16
NETWORK_GATEWAY=10.88.0.1



# Discovery Service (DNS)
DISCOVERY_SERVICE_IPV4_ADDRESS=10.88.5.1
DISCOVERY_DNS_SEARCH_DOMAIN="service.sentiric.cloud"

# ==============================================================================
# ğŸ§  LLM SERVICE YAPILANDIRMASI
# ==============================================================================
# Service Addresses
LLM_LLAMA_SERVICE_HOST=llm-llama-service
LLM_LLAMA_SERVICE_IPV4_ADDRESS=10.88.60.7
LLM_LLAMA_SERVICE_HTTP_PORT=16070
LLM_LLAMA_SERVICE_GRPC_PORT=16071
LLM_LLAMA_SERVICE_METRICS_PORT=16072
LLM_LLAMA_SERVICE_LISTEN_ADDRESS=0.0.0.0

# Model yÃ¶netimi
LLM_LLAMA_SERVICE_LOG_LEVEL=info
LLM_LLAMA_SERVICE_MODEL_DIR=/models

# ------------------------------------------------------------------------------
# [YENÄ° SÄ°STEM] Profil TabanlÄ± YÃ¶netim (profiles.json)
# ------------------------------------------------------------------------------
# Sistem artÄ±k modelleri 'models/profiles.json' dosyasÄ±ndan okur ve yÃ¶netir.
# AÅŸaÄŸÄ±daki model ayarlarÄ±, SADECE profil dosyasÄ± bulunamazsa veya okunamazsa
# "Fallback" (Yedek) olarak kullanÄ±lÄ±r.
#
# VarsayÄ±lan Yedek Model: Llama-3.2-3B (HÄ±zlÄ± ve DÃ¼ÅŸÃ¼k VRAM)
# ------------------------------------------------------------------------------

LLM_LLAMA_SERVICE_MODEL_ID=Qwen/Qwen2.5-3B-Instruct-GGUF
LLM_LLAMA_SERVICE_MODEL_FILENAME=qwen2.5-3b-instruct-q5_k_m.gguf

# --- Performans VarsayÄ±lanlarÄ± (Fallback) ---
# Bu deÄŸerler de profil tarafÄ±ndan ezilir.
# GPU KatmanlarÄ±
# Llama 3.2 3B (KÃ¼Ã§Ã¼k Model): 100 (Hepsi GPU'da)
# Llama 3.1 8B (BÃ¼yÃ¼k Model): 6GB kartta sadece ~10-15 katman sÄ±ÄŸar. Geriye kalan CPU'da Ã§alÄ±ÅŸÄ±r.
# Otomatik algÄ±lama iÃ§in yÃ¼ksek bir deÄŸer bÄ±rakabiliriz, OOM olursa dÃ¼ÅŸÃ¼rÃ¼rÃ¼z.
LLM_LLAMA_SERVICE_GPU_LAYERS=100       # -1 veya 100: Hepsi GPU'da
# Multitask (STT+TTS+LLM) iÃ§in 4096 idealdir.
# Sadece LLM Ã§alÄ±ÅŸacaksa 8192 yapÄ±labilir.
LLM_LLAMA_SERVICE_CONTEXT_SIZE=4096    # Standart Context
LLM_LLAMA_SERVICE_THREADS=1             # CPU Thread SayÄ±sÄ±
LLM_LLAMA_SERVICE_THREADS_BATCH=1

# --- Bellek Optimizasyonu ---
LLM_LLAMA_SERVICE_USE_MMAP=true         # Model yÃ¼klemesini hÄ±zlandÄ±rÄ±r
LLM_LLAMA_SERVICE_KV_OFFLOAD=true       # KV Cache'i GPU'ya taÅŸÄ±r (HÄ±z iÃ§in kritik)
LLM_LLAMA_SERVICE_NUMA=disabled         # NUMA desteÄŸi (Genellikle disabled)
LLM_LLAMA_SERVICE_FLASH_ATTN=true       # Flash Attention (VRAM tasarrufu)

# --- Dynamic Batching & EÅŸzamanlÄ±lÄ±k ---
# Bu ayarlar globaldir ve profillerden baÄŸÄ±msÄ±z Ã§alÄ±ÅŸÄ±r.
# [KRÄ°TÄ°K] EÅŸzamanlÄ±lÄ±k AyarÄ±
# 6GB VRAM iÃ§in bunu MUTLAKA 1 yapmalÄ±sÄ±nÄ±z. 
# 8 yaparsanÄ±z 8 kat daha fazla KV Cache belleÄŸi harcar ve OOM verir.
# Prod (12GB+) ortamÄ±nda 2 veya 4 yapabilirsiniz.
LLM_LLAMA_SERVICE_ENABLE_BATCHING=true
LLM_LLAMA_SERVICE_MAX_BATCH_SIZE=1       # EÅŸzamanlÄ± iÅŸlenebilecek maksimum istek
LLM_LLAMA_SERVICE_BATCH_TIMEOUT_MS=5    # DÃ¼ÅŸÃ¼k gecikme iÃ§in bekleme sÃ¼resi
LLM_LLAMA_SERVICE_ENABLE_WARM_UP=true   # BaÅŸlangÄ±Ã§ta GPU'yu Ä±sÄ±tÄ±r

# --- Sampling VarsayÄ±lanlarÄ± ---
# Ä°stek iÃ§inde parametre gelmezse bunlar kullanÄ±lÄ±r.
LLM_LLAMA_SERVICE_DEFAULT_MAX_TOKENS=1024
LLM_LLAMA_SERVICE_DEFAULT_TEMPERATURE=0.7
LLM_LLAMA_SERVICE_DEFAULT_TOP_K=40
LLM_LLAMA_SERVICE_DEFAULT_TOP_P=0.95
LLM_LLAMA_SERVICE_DEFAULT_REPEAT_PENALTY=1.1

# --- Gateway Integration ---
LLM_WORKER_GROUP="default"
# LLM_GATEWAY_ADDRESS="10.88.x.x:50051" # Opsiyonel

# --- GÃ¼venlik ---
LLM_LLAMA_SERVICE_CERT_PATH=/sentiric-certificates/certs/llm-llama-service-chain.crt
LLM_LLAMA_SERVICE_KEY_PATH=/sentiric-certificates/certs/llm-llama-service.key