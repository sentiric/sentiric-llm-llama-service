#!/bin/bash
set -e

# ==============================================================================
# Sentiric LLM Service - GeliÅŸmiÅŸ Test ve Ã–rnek KullanÄ±m Script'i (v3.0)
# ==============================================================================
#
# Bu script, llm-llama-service'e zengin baÄŸlam (context) iÃ§eren RAG ve
# konuÅŸma geÃ§miÅŸi sorgularÄ± gÃ¶ndermeyi kolaylaÅŸtÄ±rÄ±r.
#
# KullanÄ±m:
#   ./run_request.sh [seÃ§enekler] "<sorgu>"
#
# SeÃ§enekler:
#   -c, --cpu          : Testi CPU geliÅŸtirme ortamÄ±nda Ã§alÄ±ÅŸtÄ±rÄ±r. (VarsayÄ±lan: GPU)
#   -f, --file <path>  : RAG context'i olarak kullanÄ±lacak dosyanÄ±n yolu.
#   -h, --history <json> : JSON formatÄ±nda konuÅŸma geÃ§miÅŸi.
#
# Ã–rnekler:
#   ./run_request.sh -f examples/health_service_context.txt "HastanÄ±n son durumu nedir?"
#   ./run_request.sh --history '[{"role":"user","content":"BaÅŸkent neresi?"},{"role":"assistant","content":"Ankara."}]' "NÃ¼fusu ne kadar?"
# ==============================================================================

# --- DeÄŸiÅŸkenleri ve VarsayÄ±lanlarÄ± Ayarla ---
DOCKER_CMD_BASE="docker compose"
DOCKER_CMD_FLAGS_GPU="-f docker-compose.run.gpu.yml"
DOCKER_CMD_FLAGS_CPU=""
TARGET_SERVICE="llm-cli"
USE_GPU=true
RAG_CONTEXT=""
HISTORY_JSON=""
QUERY=""

# --- Komut SatÄ±rÄ± ArgÃ¼manlarÄ±nÄ± Ä°ÅŸle ---
while [[ "$#" -gt 0 ]]; do
    case $1 in
        -c|--cpu) USE_GPU=false; shift ;;
        -f|--file) RAG_CONTEXT=$(cat "$2"); shift 2 ;;
        -h|--history) HISTORY_JSON="$2"; shift 2 ;;
        *) QUERY="$1"; shift ;;
    esac
done

if [ -z "$QUERY" ]; then
    echo "âŒ HATA: Sorgu metni belirtilmedi."
    echo "KullanÄ±m: $0 [-c] [-f FILE] [-h JSON] <sorgu>"
    exit 1
fi

# Ortama gÃ¶re Docker Compose bayraklarÄ±nÄ± seÃ§
if [ "$USE_GPU" = true ]; then
    DOCKER_CMD_FLAGS="$DOCKER_CMD_FLAGS_GPU"
    echo "â„¹ï¸ GPU modu kullanÄ±lÄ±yor."
else
    DOCKER_CMD_FLAGS="$DOCKER_CMD_FLAGS_CPU"
    echo "â„¹ï¸ CPU modu seÃ§ildi."
fi

# --- llm_cli iÃ§in argÃ¼manlarÄ± oluÅŸtur ---
CLI_ARGS="generate \"${QUERY}\""

if [ -n "$RAG_CONTEXT" ]; then
    CLI_ARGS+=" --rag-context \"${RAG_CONTEXT}\""
fi

if [ -n "$HISTORY_JSON" ]; then
    CLI_ARGS+=" --history '${HISTORY_JSON}'"
fi

# --- Testi Ã‡alÄ±ÅŸtÄ±r ---
echo ""
echo "ğŸ‘¤ KullanÄ±cÄ± Sorusu: ${QUERY}"
echo "----------------------------------------------------"

# Final komutunu birleÅŸtir ve Ã§alÄ±ÅŸtÄ±r.
# `eval` kullanmak, argÃ¼manlardaki tÄ±rnak iÅŸaretlerini doÄŸru bir ÅŸekilde iÅŸlemesini saÄŸlar.
eval "$DOCKER_CMD_BASE $DOCKER_CMD_FLAGS run --rm $TARGET_SERVICE llm_cli $CLI_ARGS"
